{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "df=pd.read_csv(\"D:/College/Hackru/one_hot_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14741, 5198)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_pack_size_ml_g</th>\n",
       "      <th>unit_pack_size_ml_g</th>\n",
       "      <th>price_per_100g_ml_dollars</th>\n",
       "      <th>ci 77220</th>\n",
       "      <th>aqua</th>\n",
       "      <th>sorbitol</th>\n",
       "      <th>hydrated silica</th>\n",
       "      <th>sodium lauryl sulfate</th>\n",
       "      <th>flavor</th>\n",
       "      <th>cellulose gum</th>\n",
       "      <th>...</th>\n",
       "      <th>company_Brand 990</th>\n",
       "      <th>company_Brand 991</th>\n",
       "      <th>company_Brand 992</th>\n",
       "      <th>company_Brand 993</th>\n",
       "      <th>company_Brand 994</th>\n",
       "      <th>company_Brand 995</th>\n",
       "      <th>company_Brand 996</th>\n",
       "      <th>company_Brand 997</th>\n",
       "      <th>company_Brand 998</th>\n",
       "      <th>company_Brand 999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_pack_size_ml_g  unit_pack_size_ml_g  price_per_100g_ml_dollars  \\\n",
       "0                 130.0                130.0                       0.32   \n",
       "1                  90.0                 90.0                       1.22   \n",
       "2                 120.0                120.0                       1.26   \n",
       "3                 100.0                100.0                       4.92   \n",
       "4                 160.0                160.0                       0.79   \n",
       "\n",
       "   ci 77220  aqua  sorbitol  hydrated silica  sodium lauryl sulfate  flavor  \\\n",
       "0         1     1         1                1                      1       1   \n",
       "1         1     1         1                0                      1       0   \n",
       "2         0     1         1                1                      0       1   \n",
       "3         0     1         1                1                      1       0   \n",
       "4         0     1         1                1                      1       0   \n",
       "\n",
       "   cellulose gum  ...  company_Brand 990  company_Brand 991  \\\n",
       "0              1  ...                  0                  0   \n",
       "1              1  ...                  0                  0   \n",
       "2              1  ...                  0                  0   \n",
       "3              1  ...                  0                  0   \n",
       "4              0  ...                  0                  0   \n",
       "\n",
       "   company_Brand 992  company_Brand 993  company_Brand 994  company_Brand 995  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   company_Brand 996  company_Brand 997  company_Brand 998  company_Brand 999  \n",
       "0                  0                  0                  0                  0  \n",
       "1                  0                  0                  0                  0  \n",
       "2                  0                  0                  0                  0  \n",
       "3                  0                  0                  0                  0  \n",
       "4                  0                  0                  0                  0  \n",
       "\n",
       "[5 rows x 5198 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding columns that have string values.\n",
    "\n",
    "for col_name in df.columns:\n",
    "    #print(col_name)\n",
    "    #print(df[col_name])\n",
    "    if df[col_name].dtypes=='object':\n",
    "        a=df[col_name].unique()\n",
    "        a=len(a)\n",
    "        print(col_name + \" has \"+str(a)+\" unique values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_pack_size_ml_g</th>\n",
       "      <th>unit_pack_size_ml_g</th>\n",
       "      <th>price_per_100g_ml_dollars</th>\n",
       "      <th>ci 77220</th>\n",
       "      <th>aqua</th>\n",
       "      <th>sorbitol</th>\n",
       "      <th>hydrated silica</th>\n",
       "      <th>sodium lauryl sulfate</th>\n",
       "      <th>flavor</th>\n",
       "      <th>cellulose gum</th>\n",
       "      <th>...</th>\n",
       "      <th>company_Brand 990</th>\n",
       "      <th>company_Brand 991</th>\n",
       "      <th>company_Brand 992</th>\n",
       "      <th>company_Brand 993</th>\n",
       "      <th>company_Brand 994</th>\n",
       "      <th>company_Brand 995</th>\n",
       "      <th>company_Brand 996</th>\n",
       "      <th>company_Brand 997</th>\n",
       "      <th>company_Brand 998</th>\n",
       "      <th>company_Brand 999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.058484</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.040447</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.053975</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.044956</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009360</td>\n",
       "      <td>0.055778</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.056229</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>0.021826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 5198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_pack_size_ml_g  unit_pack_size_ml_g  price_per_100g_ml_dollars  \\\n",
       "0               0.009828             0.058484                   0.001230   \n",
       "1               0.006708             0.040447                   0.004802   \n",
       "2               0.009048             0.053975                   0.004961   \n",
       "3               0.007488             0.044956                   0.019485   \n",
       "4               0.012168             0.072011                   0.003095   \n",
       "5               0.009360             0.055778                   0.015239   \n",
       "6               0.009438             0.056229                   0.009445   \n",
       "7               0.005538             0.033683                   0.010318   \n",
       "8               0.005538             0.033683                   0.020914   \n",
       "9               0.005538             0.033683                   0.021826   \n",
       "10              0.005538             0.033683                   0.018572   \n",
       "11              0.005538             0.033683                   0.014842   \n",
       "\n",
       "    ci 77220  aqua  sorbitol  hydrated silica  sodium lauryl sulfate  flavor  \\\n",
       "0        1.0   1.0       1.0              1.0                    1.0     1.0   \n",
       "1        1.0   1.0       1.0              0.0                    1.0     0.0   \n",
       "2        0.0   1.0       1.0              1.0                    0.0     1.0   \n",
       "3        0.0   1.0       1.0              1.0                    1.0     0.0   \n",
       "4        0.0   1.0       1.0              1.0                    1.0     0.0   \n",
       "5        0.0   1.0       1.0              1.0                    1.0     0.0   \n",
       "6        0.0   1.0       1.0              1.0                    0.0     1.0   \n",
       "7        0.0   1.0       1.0              1.0                    1.0     0.0   \n",
       "8        0.0   1.0       1.0              1.0                    0.0     0.0   \n",
       "9        0.0   1.0       1.0              1.0                    1.0     0.0   \n",
       "10       0.0   1.0       1.0              1.0                    1.0     0.0   \n",
       "11       1.0   1.0       1.0              1.0                    1.0     0.0   \n",
       "\n",
       "    cellulose gum  ...  company_Brand 990  company_Brand 991  \\\n",
       "0             1.0  ...                0.0                0.0   \n",
       "1             1.0  ...                0.0                0.0   \n",
       "2             1.0  ...                0.0                0.0   \n",
       "3             1.0  ...                0.0                0.0   \n",
       "4             0.0  ...                0.0                0.0   \n",
       "5             0.0  ...                0.0                0.0   \n",
       "6             1.0  ...                0.0                0.0   \n",
       "7             1.0  ...                0.0                0.0   \n",
       "8             0.0  ...                0.0                0.0   \n",
       "9             1.0  ...                0.0                0.0   \n",
       "10            1.0  ...                0.0                0.0   \n",
       "11            1.0  ...                0.0                0.0   \n",
       "\n",
       "    company_Brand 992  company_Brand 993  company_Brand 994  \\\n",
       "0                 0.0                0.0                0.0   \n",
       "1                 0.0                0.0                0.0   \n",
       "2                 0.0                0.0                0.0   \n",
       "3                 0.0                0.0                0.0   \n",
       "4                 0.0                0.0                0.0   \n",
       "5                 0.0                0.0                0.0   \n",
       "6                 0.0                0.0                0.0   \n",
       "7                 0.0                0.0                0.0   \n",
       "8                 0.0                0.0                0.0   \n",
       "9                 0.0                0.0                0.0   \n",
       "10                0.0                0.0                0.0   \n",
       "11                0.0                0.0                0.0   \n",
       "\n",
       "    company_Brand 995  company_Brand 996  company_Brand 997  \\\n",
       "0                 0.0                0.0                0.0   \n",
       "1                 0.0                0.0                0.0   \n",
       "2                 0.0                0.0                0.0   \n",
       "3                 0.0                0.0                0.0   \n",
       "4                 0.0                0.0                0.0   \n",
       "5                 0.0                0.0                0.0   \n",
       "6                 0.0                0.0                0.0   \n",
       "7                 0.0                0.0                0.0   \n",
       "8                 0.0                0.0                0.0   \n",
       "9                 0.0                0.0                0.0   \n",
       "10                0.0                0.0                0.0   \n",
       "11                0.0                0.0                0.0   \n",
       "\n",
       "    company_Brand 998  company_Brand 999  \n",
       "0                 0.0                0.0  \n",
       "1                 0.0                0.0  \n",
       "2                 0.0                0.0  \n",
       "3                 0.0                0.0  \n",
       "4                 0.0                0.0  \n",
       "5                 0.0                0.0  \n",
       "6                 0.0                0.0  \n",
       "7                 0.0                0.0  \n",
       "8                 0.0                0.0  \n",
       "9                 0.0                0.0  \n",
       "10                0.0                0.0  \n",
       "11                0.0                0.0  \n",
       "\n",
       "[12 rows x 5198 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)\n",
    "df_scaled.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5198\n"
     ]
    }
   ],
   "source": [
    "column_names=list(df) \n",
    "print(len(column_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_pack_size_ml_g</th>\n",
       "      <th>unit_pack_size_ml_g</th>\n",
       "      <th>ci 77220</th>\n",
       "      <th>aqua</th>\n",
       "      <th>sorbitol</th>\n",
       "      <th>hydrated silica</th>\n",
       "      <th>sodium lauryl sulfate</th>\n",
       "      <th>flavor</th>\n",
       "      <th>cellulose gum</th>\n",
       "      <th>magnesium aluminum silicate</th>\n",
       "      <th>...</th>\n",
       "      <th>company_Brand 990</th>\n",
       "      <th>company_Brand 991</th>\n",
       "      <th>company_Brand 992</th>\n",
       "      <th>company_Brand 993</th>\n",
       "      <th>company_Brand 994</th>\n",
       "      <th>company_Brand 995</th>\n",
       "      <th>company_Brand 996</th>\n",
       "      <th>company_Brand 997</th>\n",
       "      <th>company_Brand 998</th>\n",
       "      <th>company_Brand 999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12570</th>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>12825.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2218.01</td>\n",
       "      <td>2218.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>90.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>370.00</td>\n",
       "      <td>185.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>190.00</td>\n",
       "      <td>190.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082</th>\n",
       "      <td>175.00</td>\n",
       "      <td>175.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>125.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>190.00</td>\n",
       "      <td>190.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 5197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_pack_size_ml_g  unit_pack_size_ml_g  ci 77220  aqua  sorbitol  \\\n",
       "12570                 75.00                75.00         1     1         1   \n",
       "4254               12825.00                75.00         0     1         1   \n",
       "486                 2218.01              2218.01         0     1         0   \n",
       "742                  200.00               200.00         1     1         1   \n",
       "4837                  90.00                90.00         1     1         1   \n",
       "7647                  80.00                80.00         1     1         1   \n",
       "1737                  75.00                75.00         0     1         1   \n",
       "717                  370.00               185.00         1     1         1   \n",
       "318                  190.00               190.00         1     1         1   \n",
       "9082                 175.00               175.00         1     0         1   \n",
       "9462                 125.00               125.00         0     1         1   \n",
       "4860                 190.00               190.00         1     1         1   \n",
       "\n",
       "       hydrated silica  sodium lauryl sulfate  flavor  cellulose gum  \\\n",
       "12570                1                      1       0              0   \n",
       "4254                 1                      0       0              0   \n",
       "486                  0                      1       0              1   \n",
       "742                  1                      1       0              1   \n",
       "4837                 1                      1       0              1   \n",
       "7647                 1                      0       0              1   \n",
       "1737                 0                      1       0              1   \n",
       "717                  0                      1       0              0   \n",
       "318                  1                      0       0              1   \n",
       "9082                 1                      1       0              1   \n",
       "9462                 1                      1       0              0   \n",
       "4860                 0                      1       0              0   \n",
       "\n",
       "       magnesium aluminum silicate  ...  company_Brand 990  company_Brand 991  \\\n",
       "12570                            0  ...                  0                  0   \n",
       "4254                             0  ...                  0                  0   \n",
       "486                              0  ...                  0                  0   \n",
       "742                              0  ...                  0                  0   \n",
       "4837                             0  ...                  0                  0   \n",
       "7647                             0  ...                  0                  0   \n",
       "1737                             0  ...                  0                  0   \n",
       "717                              0  ...                  0                  0   \n",
       "318                              1  ...                  0                  0   \n",
       "9082                             0  ...                  0                  0   \n",
       "9462                             0  ...                  0                  0   \n",
       "4860                             0  ...                  0                  0   \n",
       "\n",
       "       company_Brand 992  company_Brand 993  company_Brand 994  \\\n",
       "12570                  0                  0                  0   \n",
       "4254                   0                  0                  0   \n",
       "486                    0                  0                  0   \n",
       "742                    0                  0                  0   \n",
       "4837                   0                  0                  0   \n",
       "7647                   0                  0                  0   \n",
       "1737                   0                  0                  0   \n",
       "717                    0                  0                  0   \n",
       "318                    0                  0                  0   \n",
       "9082                   0                  0                  0   \n",
       "9462                   0                  0                  0   \n",
       "4860                   0                  0                  0   \n",
       "\n",
       "       company_Brand 995  company_Brand 996  company_Brand 997  \\\n",
       "12570                  0                  0                  0   \n",
       "4254                   0                  0                  0   \n",
       "486                    0                  0                  0   \n",
       "742                    0                  0                  0   \n",
       "4837                   0                  0                  0   \n",
       "7647                   0                  0                  0   \n",
       "1737                   0                  0                  0   \n",
       "717                    0                  0                  0   \n",
       "318                    0                  0                  0   \n",
       "9082                   0                  0                  0   \n",
       "9462                   0                  0                  0   \n",
       "4860                   0                  0                  0   \n",
       "\n",
       "       company_Brand 998  company_Brand 999  \n",
       "12570                  0                  0  \n",
       "4254                   0                  0  \n",
       "486                    0                  0  \n",
       "742                    0                  0  \n",
       "4837                   0                  0  \n",
       "7647                   0                  0  \n",
       "1737                   0                  0  \n",
       "717                    0                  0  \n",
       "318                    0                  0  \n",
       "9082                   0                  0  \n",
       "9462                   0                  0  \n",
       "4860                   0                  0  \n",
       "\n",
       "[12 rows x 5197 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features=df_scaled[column_names].values\n",
    "all_classes=df_scaled['price_per_100g_ml_dollars'].values\n",
    "\n",
    "\n",
    "df=df.sort_values(by=['price_per_100g_ml_dollars'])\n",
    "X = df.drop('price_per_100g_ml_dollars',1)\n",
    "y = df['price_per_100g_ml_dollars']\n",
    "\n",
    "\n",
    "\n",
    "df=df.drop(columns='price_per_100g_ml_dollars')\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197\n"
     ]
    }
   ],
   "source": [
    "print(len(df_scaled.columns)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "#X_train,X_train_lr, y_train, y_train_lr = train_test_split(X_train,y_train,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Worked\n",
      "About to start estimator\n",
      "Output layer\n",
      "Train on 11792 samples\n",
      "Epoch 1/200\n",
      "11792/11792 [==============================] - 3s 284us/sample - loss: 28.5674 - mae: 2.6444\n",
      "Epoch 2/200\n",
      "11792/11792 [==============================] - 2s 177us/sample - loss: 18.8654 - mae: 2.2293\n",
      "Epoch 3/200\n",
      "11792/11792 [==============================] - 3s 240us/sample - loss: 15.2789 - mae: 2.0497\n",
      "Epoch 4/200\n",
      "11792/11792 [==============================] - 3s 233us/sample - loss: 13.3450 - mae: 1.9515\n",
      "Epoch 5/200\n",
      "11792/11792 [==============================] - 2s 200us/sample - loss: 11.8883 - mae: 1.8029\n",
      "Epoch 6/200\n",
      "11792/11792 [==============================] - 2s 184us/sample - loss: 10.8791 - mae: 1.7622\n",
      "Epoch 7/200\n",
      "11792/11792 [==============================] - 3s 290us/sample - loss: 10.0765 - mae: 1.7023\n",
      "Epoch 8/200\n",
      "11792/11792 [==============================] - 3s 218us/sample - loss: 9.4855 - mae: 1.6598\n",
      "Epoch 9/200\n",
      "11792/11792 [==============================] - 3s 244us/sample - loss: 8.9314 - mae: 1.6168\n",
      "Epoch 10/200\n",
      "11792/11792 [==============================] - 2s 185us/sample - loss: 8.8947 - mae: 1.6430\n",
      "Epoch 11/200\n",
      "11792/11792 [==============================] - 2s 203us/sample - loss: 8.2585 - mae: 1.5526\n",
      "Epoch 12/200\n",
      "11792/11792 [==============================] - 2s 194us/sample - loss: 7.9211 - mae: 1.5210\n",
      "Epoch 13/200\n",
      "11792/11792 [==============================] - 2s 211us/sample - loss: 7.6355 - mae: 1.5215\n",
      "Epoch 14/200\n",
      "11792/11792 [==============================] - 3s 270us/sample - loss: 7.2599 - mae: 1.4664\n",
      "Epoch 15/200\n",
      "11792/11792 [==============================] - 3s 215us/sample - loss: 7.1444 - mae: 1.4753s - loss: 7.2691 - mae: 1\n",
      "Epoch 16/200\n",
      "11792/11792 [==============================] - 3s 266us/sample - loss: 7.0982 - mae: 1.4737s - loss: 7.5\n",
      "Epoch 17/200\n",
      "11792/11792 [==============================] - 3s 242us/sample - loss: 6.7702 - mae: 1.4311\n",
      "Epoch 18/200\n",
      "11792/11792 [==============================] - 3s 264us/sample - loss: 6.3908 - mae: 1.4079\n",
      "Epoch 19/200\n",
      "11792/11792 [==============================] - 3s 283us/sample - loss: 6.3568 - mae: 1.4256\n",
      "Epoch 20/200\n",
      "11792/11792 [==============================] - 3s 284us/sample - loss: 6.1700 - mae: 1.3925\n",
      "Epoch 21/200\n",
      "11792/11792 [==============================] - 3s 272us/sample - loss: 6.1437 - mae: 1.4005\n",
      "Epoch 22/200\n",
      "11792/11792 [==============================] - 3s 280us/sample - loss: 5.8756 - mae: 1.3943s - loss: 6.1120 - \n",
      "Epoch 23/200\n",
      "11792/11792 [==============================] - 3s 258us/sample - loss: 5.7412 - mae: 1.3685\n",
      "Epoch 24/200\n",
      "11792/11792 [==============================] - 3s 230us/sample - loss: 5.6163 - mae: 1.3542\n",
      "Epoch 25/200\n",
      "11792/11792 [==============================] - 3s 232us/sample - loss: 5.3226 - mae: 1.3495\n",
      "Epoch 26/200\n",
      "11792/11792 [==============================] - 4s 300us/sample - loss: 5.0785 - mae: 1.3183\n",
      "Epoch 27/200\n",
      "11792/11792 [==============================] - 3s 281us/sample - loss: 5.1550 - mae: 1.3298\n",
      "Epoch 28/200\n",
      "11792/11792 [==============================] - 3s 264us/sample - loss: 5.2032 - mae: 1.3504\n",
      "Epoch 29/200\n",
      "11792/11792 [==============================] - 3s 277us/sample - loss: 5.0262 - mae: 1.3097\n",
      "Epoch 30/200\n",
      "11792/11792 [==============================] - 3s 276us/sample - loss: 4.8983 - mae: 1.2943\n",
      "Epoch 31/200\n",
      "11792/11792 [==============================] - 3s 282us/sample - loss: 4.8666 - mae: 1.3090\n",
      "Epoch 32/200\n",
      "11792/11792 [==============================] - 3s 280us/sample - loss: 4.7531 - mae: 1.2922s - los\n",
      "Epoch 33/200\n",
      "11792/11792 [==============================] - 3s 293us/sample - loss: 4.7141 - mae: 1.2913\n",
      "Epoch 34/200\n",
      "11792/11792 [==============================] - 3s 280us/sample - loss: 4.6301 - mae: 1.2838s - loss: 4.5104 - mae:\n",
      "Epoch 35/200\n",
      "11792/11792 [==============================] - 3s 282us/sample - loss: 4.6379 - mae: 1.2888\n",
      "Epoch 36/200\n",
      "11792/11792 [==============================] - 3s 295us/sample - loss: 4.5794 - mae: 1.2642\n",
      "Epoch 37/200\n",
      "11792/11792 [==============================] - 3s 282us/sample - loss: 4.5574 - mae: 1.2633\n",
      "Epoch 38/200\n",
      "11792/11792 [==============================] - 3s 291us/sample - loss: 4.6734 - mae: 1.2843\n",
      "Epoch 39/200\n",
      "11792/11792 [==============================] - 4s 324us/sample - loss: 4.4208 - mae: 1.2465\n",
      "Epoch 40/200\n",
      "11792/11792 [==============================] - 4s 322us/sample - loss: 4.4093 - mae: 1.2612\n",
      "Epoch 41/200\n",
      "11792/11792 [==============================] - 3s 284us/sample - loss: 4.2794 - mae: 1.2326\n",
      "Epoch 42/200\n",
      "11792/11792 [==============================] - 4s 303us/sample - loss: 4.3691 - mae: 1.2529\n",
      "Epoch 43/200\n",
      "11792/11792 [==============================] - 3s 292us/sample - loss: 4.2062 - mae: 1.2367\n",
      "Epoch 44/200\n",
      "11792/11792 [==============================] - 4s 298us/sample - loss: 4.2605 - mae: 1.2392\n",
      "Epoch 45/200\n",
      "11792/11792 [==============================] - 3s 292us/sample - loss: 4.3401 - mae: 1.2466\n",
      "Epoch 46/200\n",
      "11792/11792 [==============================] - 3s 293us/sample - loss: 4.3454 - mae: 1.2430\n",
      "Epoch 47/200\n",
      "11792/11792 [==============================] - 4s 298us/sample - loss: 4.1863 - mae: 1.2232\n",
      "Epoch 48/200\n",
      "11792/11792 [==============================] - 3s 293us/sample - loss: 4.1803 - mae: 1.2035\n",
      "Epoch 49/200\n",
      "11792/11792 [==============================] - 3s 287us/sample - loss: 4.2687 - mae: 1.2429\n",
      "Epoch 50/200\n",
      "11792/11792 [==============================] - 3s 293us/sample - loss: 4.0935 - mae: 1.2039\n",
      "Epoch 51/200\n",
      "11792/11792 [==============================] - 4s 298us/sample - loss: 4.0072 - mae: 1.1990s - loss: 3.8 - ETA: 0s - loss: 4.0000 \n",
      "Epoch 52/200\n",
      "11792/11792 [==============================] - 4s 333us/sample - loss: 4.1066 - mae: 1.2091\n",
      "Epoch 53/200\n",
      "11792/11792 [==============================] - 4s 311us/sample - loss: 3.9939 - mae: 1.2036\n",
      "Epoch 54/200\n",
      "11792/11792 [==============================] - 4s 298us/sample - loss: 4.0466 - mae: 1.2058\n",
      "Epoch 55/200\n",
      "11792/11792 [==============================] - 4s 313us/sample - loss: 4.0818 - mae: 1.1942\n",
      "Epoch 56/200\n",
      "11792/11792 [==============================] - 3s 290us/sample - loss: 3.9812 - mae: 1.1932s -\n",
      "Epoch 57/200\n",
      "11792/11792 [==============================] - 3s 295us/sample - loss: 4.0706 - mae: 1.2088\n",
      "Epoch 58/200\n",
      "11792/11792 [==============================] - 3s 294us/sample - loss: 4.1138 - mae: 1.2187s - loss: 4.0038 - mae - ETA: 0s - loss: 4.0500 - mae: 1.20 - ETA: 0s - loss: 4.0211 - \n",
      "Epoch 59/200\n",
      "11792/11792 [==============================] - 4s 306us/sample - loss: 4.1182 - mae: 1.2089\n",
      "Epoch 60/200\n",
      "11792/11792 [==============================] - 3s 294us/sample - loss: 3.9416 - mae: 1.1806\n",
      "Epoch 61/200\n",
      "11792/11792 [==============================] - 4s 304us/sample - loss: 3.9229 - mae: 1.1825\n",
      "Epoch 62/200\n",
      "11792/11792 [==============================] - 3s 292us/sample - loss: 3.8549 - mae: 1.1771s - loss: 3.8115 - ETA: 1s\n",
      "Epoch 63/200\n",
      "11792/11792 [==============================] - 4s 303us/sample - loss: 3.8885 - mae: 1.1838\n",
      "Epoch 64/200\n",
      "11792/11792 [==============================] - 4s 308us/sample - loss: 3.8324 - mae: 1.1696\n",
      "Epoch 65/200\n",
      "11792/11792 [==============================] - 4s 304us/sample - loss: 3.9527 - mae: 1.1820s -  - ET\n",
      "Epoch 66/200\n",
      "11792/11792 [==============================] - 4s 303us/sample - loss: 3.9964 - mae: 1.1847s - loss: 3.6\n",
      "Epoch 67/200\n",
      "11792/11792 [==============================] - 4s 303us/sample - loss: 3.8726 - mae: 1.1721- ETA: 1s - loss\n",
      "Epoch 68/200\n",
      "11792/11792 [==============================] - 4s 301us/sample - loss: 3.8889 - mae: 1.1734\n",
      "Epoch 69/200\n",
      "11792/11792 [==============================] - 4s 305us/sample - loss: 3.7783 - mae: 1.1585\n",
      "Epoch 70/200\n",
      "11792/11792 [==============================] - 3s 232us/sample - loss: 3.7927 - mae: 1.1574\n",
      "Epoch 71/200\n",
      "11792/11792 [==============================] - 3s 229us/sample - loss: 3.8330 - mae: 1.1735\n",
      "Epoch 72/200\n",
      "11792/11792 [==============================] - 3s 230us/sample - loss: 3.8864 - mae: 1.1820s  - ETA: 1s - loss: 3.7307 - mae: 1.16 - ETA: 0s - loss: 3.7146 - mae: 1.1 - ETA: 0s - loss: 3.7423 \n",
      "Epoch 73/200\n",
      "11792/11792 [==============================] - 2s 180us/sample - loss: 3.8870 - mae: 1.1690\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11792/11792 [==============================] - 2s 174us/sample - loss: 3.7381 - mae: 1.1522\n",
      "Epoch 75/200\n",
      "11792/11792 [==============================] - 2s 184us/sample - loss: 3.7683 - mae: 1.1547\n",
      "Epoch 76/200\n",
      "11792/11792 [==============================] - 2s 177us/sample - loss: 3.8602 - mae: 1.1716\n",
      "Epoch 77/200\n",
      "11792/11792 [==============================] - 2s 177us/sample - loss: 3.8634 - mae: 1.1605\n",
      "Epoch 78/200\n",
      "11792/11792 [==============================] - 2s 170us/sample - loss: 3.6844 - mae: 1.1433\n",
      "Epoch 79/200\n",
      "11792/11792 [==============================] - 2s 184us/sample - loss: 3.7235 - mae: 1.1526\n",
      "Epoch 80/200\n",
      "11792/11792 [==============================] - 2s 203us/sample - loss: 3.7028 - mae: 1.1489\n",
      "Epoch 81/200\n",
      "11792/11792 [==============================] - 2s 165us/sample - loss: 3.7133 - mae: 1.1505\n",
      "Epoch 82/200\n",
      "11792/11792 [==============================] - 2s 161us/sample - loss: 3.7171 - mae: 1.1548\n",
      "Epoch 83/200\n",
      "11792/11792 [==============================] - 2s 162us/sample - loss: 3.6975 - mae: 1.1511\n",
      "Epoch 84/200\n",
      "11792/11792 [==============================] - 2s 163us/sample - loss: 3.7522 - mae: 1.1441\n",
      "Epoch 85/200\n",
      "11792/11792 [==============================] - 2s 172us/sample - loss: 3.6765 - mae: 1.1395\n",
      "Epoch 86/200\n",
      "11792/11792 [==============================] - 3s 233us/sample - loss: 3.6889 - mae: 1.1368s - loss: 3.657\n",
      "Epoch 87/200\n",
      "11792/11792 [==============================] - 3s 215us/sample - loss: 3.8232 - mae: 1.1636\n",
      "Epoch 88/200\n",
      "11792/11792 [==============================] - 2s 180us/sample - loss: 3.6789 - mae: 1.1445\n",
      "Epoch 89/200\n",
      "11792/11792 [==============================] - 2s 172us/sample - loss: 3.7007 - mae: 1.1477\n",
      "Epoch 90/200\n",
      "11792/11792 [==============================] - 2s 173us/sample - loss: 3.6072 - mae: 1.1281\n",
      "Epoch 91/200\n",
      "11792/11792 [==============================] - 2s 173us/sample - loss: 3.6228 - mae: 1.1411\n",
      "Epoch 92/200\n",
      "11792/11792 [==============================] - 2s 181us/sample - loss: 3.6359 - mae: 1.1322\n",
      "Epoch 93/200\n",
      "11792/11792 [==============================] - 2s 182us/sample - loss: 3.7210 - mae: 1.1574\n",
      "Epoch 94/200\n",
      "11792/11792 [==============================] - 2s 184us/sample - loss: 3.6908 - mae: 1.1376\n",
      "Epoch 95/200\n",
      "11792/11792 [==============================] - 2s 179us/sample - loss: 3.6555 - mae: 1.1367\n",
      "Epoch 96/200\n",
      "11792/11792 [==============================] - 2s 182us/sample - loss: 3.5869 - mae: 1.1298\n",
      "Epoch 97/200\n",
      "11792/11792 [==============================] - 2s 171us/sample - loss: 3.8817 - mae: 1.1584\n",
      "Epoch 98/200\n",
      "11792/11792 [==============================] - 2s 175us/sample - loss: 3.7558 - mae: 1.1478\n",
      "Epoch 99/200\n",
      "11792/11792 [==============================] - 2s 178us/sample - loss: 3.5753 - mae: 1.1240\n",
      "Epoch 100/200\n",
      "11792/11792 [==============================] - 2s 181us/sample - loss: 3.6241 - mae: 1.1438\n",
      "Epoch 101/200\n",
      "11792/11792 [==============================] - 2s 183us/sample - loss: 3.5760 - mae: 1.1292\n",
      "Epoch 102/200\n",
      "11792/11792 [==============================] - 2s 174us/sample - loss: 3.6569 - mae: 1.1400\n",
      "Epoch 103/200\n",
      "11792/11792 [==============================] - 2s 178us/sample - loss: 3.6091 - mae: 1.1261\n",
      "Epoch 104/200\n",
      "11792/11792 [==============================] - 2s 173us/sample - loss: 3.6032 - mae: 1.1267\n",
      "Epoch 105/200\n",
      "11792/11792 [==============================] - 2s 174us/sample - loss: 3.5101 - mae: 1.1153\n",
      "Epoch 106/200\n",
      "11792/11792 [==============================] - 2s 183us/sample - loss: 3.4800 - mae: 1.1181\n",
      "Epoch 107/200\n",
      "11792/11792 [==============================] - 2s 202us/sample - loss: 3.6196 - mae: 1.1354\n",
      "Epoch 108/200\n",
      "11792/11792 [==============================] - 2s 190us/sample - loss: 3.6271 - mae: 1.1391\n",
      "Epoch 109/200\n",
      "11792/11792 [==============================] - 2s 180us/sample - loss: 3.5954 - mae: 1.1315\n",
      "Epoch 110/200\n",
      "11792/11792 [==============================] - 2s 204us/sample - loss: 3.5257 - mae: 1.1114\n",
      "Epoch 111/200\n",
      "11792/11792 [==============================] - 2s 179us/sample - loss: 3.6127 - mae: 1.1240\n",
      "Epoch 112/200\n",
      "11792/11792 [==============================] - 2s 185us/sample - loss: 3.5972 - mae: 1.1276\n",
      "Epoch 113/200\n",
      "11792/11792 [==============================] - 3s 240us/sample - loss: 3.5084 - mae: 1.1199\n",
      "Epoch 114/200\n",
      "11792/11792 [==============================] - 3s 248us/sample - loss: 3.6225 - mae: 1.1246\n",
      "Epoch 115/200\n",
      "11792/11792 [==============================] - 3s 249us/sample - loss: 3.6452 - mae: 1.1254\n",
      "Epoch 116/200\n",
      "11792/11792 [==============================] - 2s 200us/sample - loss: 3.4937 - mae: 1.1089\n",
      "Epoch 117/200\n",
      "11792/11792 [==============================] - 3s 230us/sample - loss: 3.5559 - mae: 1.1257\n",
      "Epoch 118/200\n",
      "11792/11792 [==============================] - 3s 291us/sample - loss: 3.4344 - mae: 1.0963s - loss: 3.2418 - m\n",
      "Epoch 119/200\n",
      "11792/11792 [==============================] - 3s 224us/sample - loss: 3.5882 - mae: 1.1272s\n",
      "Epoch 120/200\n",
      "11792/11792 [==============================] - 3s 265us/sample - loss: 3.5954 - mae: 1.1429s - loss: 3.6467 \n",
      "Epoch 121/200\n",
      "11792/11792 [==============================] - 3s 212us/sample - loss: 3.4750 - mae: 1.1087\n",
      "Epoch 122/200\n",
      "11792/11792 [==============================] - 2s 170us/sample - loss: 3.4731 - mae: 1.1074\n",
      "Epoch 123/200\n",
      "11792/11792 [==============================] - 2s 146us/sample - loss: 3.5962 - mae: 1.1311\n",
      "Epoch 124/200\n",
      "11792/11792 [==============================] - 2s 208us/sample - loss: 3.4813 - mae: 1.0998\n",
      "Epoch 125/200\n",
      "11792/11792 [==============================] - 2s 167us/sample - loss: 3.4942 - mae: 1.1078\n",
      "Epoch 126/200\n",
      "11792/11792 [==============================] - 2s 164us/sample - loss: 3.4746 - mae: 1.1095\n",
      "Epoch 127/200\n",
      "11792/11792 [==============================] - 2s 154us/sample - loss: 3.6044 - mae: 1.1259\n",
      "Epoch 128/200\n",
      "11792/11792 [==============================] - 2s 145us/sample - loss: 3.6965 - mae: 1.1337\n",
      "Epoch 129/200\n",
      "11792/11792 [==============================] - 2s 146us/sample - loss: 3.5512 - mae: 1.1236\n",
      "Epoch 130/200\n",
      "11792/11792 [==============================] - 2s 146us/sample - loss: 3.4910 - mae: 1.1115\n",
      "Epoch 131/200\n",
      "11792/11792 [==============================] - 2s 149us/sample - loss: 3.5455 - mae: 1.1030\n",
      "Epoch 132/200\n",
      "11792/11792 [==============================] - 2s 202us/sample - loss: 3.6141 - mae: 1.1167\n",
      "Epoch 133/200\n",
      "11792/11792 [==============================] - 2s 164us/sample - loss: 3.4450 - mae: 1.0977\n",
      "Epoch 134/200\n",
      "11792/11792 [==============================] - 2s 163us/sample - loss: 3.4541 - mae: 1.1061\n",
      "Epoch 135/200\n",
      "11792/11792 [==============================] - 2s 176us/sample - loss: 3.4501 - mae: 1.1104\n",
      "Epoch 136/200\n",
      "11792/11792 [==============================] - 2s 175us/sample - loss: 3.4172 - mae: 1.1027\n",
      "Epoch 137/200\n",
      "11792/11792 [==============================] - 2s 170us/sample - loss: 3.4458 - mae: 1.1180\n",
      "Epoch 138/200\n",
      "11792/11792 [==============================] - 3s 223us/sample - loss: 3.3617 - mae: 1.0928\n",
      "Epoch 139/200\n",
      "11792/11792 [==============================] - 2s 187us/sample - loss: 3.5214 - mae: 1.1142\n",
      "Epoch 140/200\n",
      "11792/11792 [==============================] - 3s 222us/sample - loss: 3.6654 - mae: 1.1334\n",
      "Epoch 141/200\n",
      "11792/11792 [==============================] - 2s 204us/sample - loss: 3.5735 - mae: 1.1275\n",
      "Epoch 142/200\n",
      "11792/11792 [==============================] - 2s 197us/sample - loss: 3.4595 - mae: 1.1048\n",
      "Epoch 143/200\n",
      "11792/11792 [==============================] - 2s 162us/sample - loss: 3.3835 - mae: 1.0949\n",
      "Epoch 144/200\n",
      "11792/11792 [==============================] - 2s 143us/sample - loss: 3.3981 - mae: 1.1019\n",
      "Epoch 145/200\n",
      "11792/11792 [==============================] - 2s 149us/sample - loss: 3.4500 - mae: 1.1046\n",
      "Epoch 146/200\n",
      "11792/11792 [==============================] - 2s 144us/sample - loss: 3.4868 - mae: 1.1067\n",
      "Epoch 147/200\n",
      "11792/11792 [==============================] - 2s 144us/sample - loss: 3.4822 - mae: 1.1066\n",
      "Epoch 148/200\n",
      "11792/11792 [==============================] - 2s 144us/sample - loss: 3.5249 - mae: 1.1152\n",
      "Epoch 149/200\n",
      "11792/11792 [==============================] - 2s 146us/sample - loss: 3.3862 - mae: 1.0876\n",
      "Epoch 150/200\n",
      "11792/11792 [==============================] - 2s 143us/sample - loss: 3.4557 - mae: 1.1092\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11792/11792 [==============================] - 2s 146us/sample - loss: 3.4655 - mae: 1.1045\n",
      "Epoch 152/200\n",
      "11792/11792 [==============================] - 2s 144us/sample - loss: 3.4834 - mae: 1.1037\n",
      "Epoch 153/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.5363 - mae: 1.1208\n",
      "Epoch 154/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.4992 - mae: 1.1058\n",
      "Epoch 155/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.5207 - mae: 1.1179\n",
      "Epoch 156/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.3858 - mae: 1.0901\n",
      "Epoch 157/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.4494 - mae: 1.1075\n",
      "Epoch 158/200\n",
      "11792/11792 [==============================] - 2s 147us/sample - loss: 3.4711 - mae: 1.1087\n",
      "Epoch 159/200\n",
      "11792/11792 [==============================] - 2s 143us/sample - loss: 3.4210 - mae: 1.1038\n",
      "Epoch 160/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.3700 - mae: 1.0904\n",
      "Epoch 161/200\n",
      "11792/11792 [==============================] - 2s 143us/sample - loss: 3.4043 - mae: 1.1012\n",
      "Epoch 162/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.5024 - mae: 1.1106\n",
      "Epoch 163/200\n",
      "11792/11792 [==============================] - 2s 143us/sample - loss: 3.3899 - mae: 1.0804\n",
      "Epoch 164/200\n",
      "11792/11792 [==============================] - 2s 143us/sample - loss: 3.4080 - mae: 1.0977\n",
      "Epoch 165/200\n",
      "11792/11792 [==============================] - 2s 150us/sample - loss: 3.4421 - mae: 1.0988\n",
      "Epoch 166/200\n",
      "11792/11792 [==============================] - 2s 147us/sample - loss: 3.4460 - mae: 1.1030\n",
      "Epoch 167/200\n",
      "11792/11792 [==============================] - 2s 143us/sample - loss: 3.4867 - mae: 1.1149\n",
      "Epoch 168/200\n",
      "11792/11792 [==============================] - 2s 173us/sample - loss: 3.3425 - mae: 1.0850\n",
      "Epoch 169/200\n",
      "11792/11792 [==============================] - 2s 188us/sample - loss: 3.3761 - mae: 1.0882s - loss: 3.310\n",
      "Epoch 170/200\n",
      "11792/11792 [==============================] - 3s 223us/sample - loss: 3.3677 - mae: 1.0904\n",
      "Epoch 171/200\n",
      "11792/11792 [==============================] - 2s 184us/sample - loss: 3.3940 - mae: 1.0993\n",
      "Epoch 172/200\n",
      "11792/11792 [==============================] - 2s 173us/sample - loss: 3.4895 - mae: 1.1092\n",
      "Epoch 173/200\n",
      "11792/11792 [==============================] - 2s 176us/sample - loss: 3.4455 - mae: 1.0986\n",
      "Epoch 174/200\n",
      "11792/11792 [==============================] - 2s 163us/sample - loss: 3.4335 - mae: 1.0953\n",
      "Epoch 175/200\n",
      "11792/11792 [==============================] - 2s 178us/sample - loss: 3.4362 - mae: 1.0982\n",
      "Epoch 176/200\n",
      "11792/11792 [==============================] - 2s 150us/sample - loss: 3.3586 - mae: 1.0955\n",
      "Epoch 177/200\n",
      "11792/11792 [==============================] - 2s 142us/sample - loss: 3.4192 - mae: 1.0930\n",
      "Epoch 178/200\n",
      "11792/11792 [==============================] - 2s 145us/sample - loss: 3.4028 - mae: 1.0928\n",
      "Epoch 179/200\n",
      "11792/11792 [==============================] - 2s 144us/sample - loss: 3.4200 - mae: 1.1039\n",
      "Epoch 180/200\n",
      "11792/11792 [==============================] - 2s 151us/sample - loss: 3.3933 - mae: 1.0813\n",
      "Epoch 181/200\n",
      "11792/11792 [==============================] - 2s 171us/sample - loss: 3.5156 - mae: 1.0990\n",
      "Epoch 182/200\n",
      "11792/11792 [==============================] - 2s 182us/sample - loss: 3.4577 - mae: 1.1103\n",
      "Epoch 183/200\n",
      "11792/11792 [==============================] - 2s 184us/sample - loss: 3.4394 - mae: 1.0974\n",
      "Epoch 184/200\n",
      "11792/11792 [==============================] - 2s 173us/sample - loss: 3.3624 - mae: 1.0909\n",
      "Epoch 185/200\n",
      "11792/11792 [==============================] - 2s 163us/sample - loss: 3.3128 - mae: 1.0706\n",
      "Epoch 186/200\n",
      "11792/11792 [==============================] - 2s 165us/sample - loss: 3.3124 - mae: 1.0753\n",
      "Epoch 187/200\n",
      "11792/11792 [==============================] - 2s 166us/sample - loss: 3.2579 - mae: 1.0692\n",
      "Epoch 188/200\n",
      "11792/11792 [==============================] - 2s 174us/sample - loss: 3.2886 - mae: 1.0776\n",
      "Epoch 189/200\n",
      "11792/11792 [==============================] - 2s 181us/sample - loss: 3.4486 - mae: 1.1071\n",
      "Epoch 190/200\n",
      "11792/11792 [==============================] - 2s 189us/sample - loss: 3.5145 - mae: 1.1095\n",
      "Epoch 191/200\n",
      "11792/11792 [==============================] - 2s 167us/sample - loss: 3.4633 - mae: 1.0996\n",
      "Epoch 192/200\n",
      "11792/11792 [==============================] - 2s 172us/sample - loss: 3.3896 - mae: 1.0839\n",
      "Epoch 193/200\n",
      "11792/11792 [==============================] - 2s 171us/sample - loss: 3.3226 - mae: 1.0798\n",
      "Epoch 194/200\n",
      "11792/11792 [==============================] - 2s 181us/sample - loss: 3.3468 - mae: 1.0877\n",
      "Epoch 195/200\n",
      "11792/11792 [==============================] - 2s 163us/sample - loss: 3.3396 - mae: 1.0838\n",
      "Epoch 196/200\n",
      "11792/11792 [==============================] - 2s 169us/sample - loss: 3.5564 - mae: 1.1162\n",
      "Epoch 197/200\n",
      "11792/11792 [==============================] - 2s 190us/sample - loss: 3.3786 - mae: 1.0920\n",
      "Epoch 198/200\n",
      "11792/11792 [==============================] - 2s 206us/sample - loss: 3.3640 - mae: 1.0810\n",
      "Epoch 199/200\n",
      "11792/11792 [==============================] - 2s 183us/sample - loss: 3.4264 - mae: 1.0953\n",
      "Epoch 200/200\n",
      "11792/11792 [==============================] - 2s 170us/sample - loss: 3.3155 - mae: 1.0734\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Dense,Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras import regularizers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#import keras_metrics\n",
    "print(\"Import Worked\")\n",
    "def create_model():\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Dense(50,input_dim=len(df_scaled.columns)-1, kernel_initializer='normal', activation='tanh', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(50,input_dim=len(df_scaled.columns)-1, kernel_initializer='normal', activation='tanh', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(50,activation='linear'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #COMPILE MODE\n",
    "    print(\"Output layer\")\n",
    "    model.compile(loss='mse', optimizer='nadam',metrics=[\"mae\"])\n",
    "    return model\n",
    " \n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "print(\"About to start estimator\")   \n",
    "\n",
    "keras_model = create_model()\n",
    "history = keras_model.fit(X_train,y_train,epochs=200, batch_size=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2949/2949 [==============================] - 0s 108us/sample - loss: 15.9890 - mae: 1.8694\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = keras_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olute_error: 0.1635 - acc: 0.0016\n",
      "Epoch 1855/2000\n",
      "3685/3685 [==============================] - 1s 309us/sample - loss: 0.0458 - mean_absolute_error: 0.1384 - acc: 0.0016\n",
      "Epoch 1856/2000\n",
      "3685/3685 [==============================] - 1s 295us/sample - loss: 0.0855 - mean_absolute_error: 0.2112 - acc: 0.0016\n",
      "Epoch 1857/2000\n",
      "3685/3685 [==============================] - 1s 278us/sample - loss: 0.0642 - mean_absolute_error: 0.1691 - acc: 0.0016\n",
      "Epoch 1858/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0534 - mean_absolute_error: 0.1553 - acc: 0.0016\n",
      "Epoch 1859/2000\n",
      "3685/3685 [==============================] - 1s 303us/sample - loss: 0.0512 - mean_absolute_error: 0.1535 - acc: 0.0016\n",
      "Epoch 1860/2000\n",
      "3685/3685 [==============================] - 1s 293us/sample - loss: 0.0510 - mean_absolute_error: 0.1529 - acc: 0.0016\n",
      "Epoch 1861/2000\n",
      "3685/3685 [==============================] - 1s 287us/sample - loss: 0.0532 - mean_absolute_error: 0.1570 - acc: 0.0016\n",
      "Epoch 1862/2000\n",
      "3685/3685 [==============================] - 1s 276us/sample - loss: 0.0607 - mean_absolute_error: 0.1662 - acc: 0.0016\n",
      "Epoch 1863/2000\n",
      "3685/3685 [==============================] - 1s 293us/sample - loss: 0.0730 - mean_absolute_error: 0.1804 - acc: 0.0016\n",
      "Epoch 1864/2000\n",
      "3685/3685 [==============================] - 1s 291us/sample - loss: 0.0569 - mean_absolute_error: 0.1637 - acc: 0.0016\n",
      "Epoch 1865/2000\n",
      "3685/3685 [==============================] - 1s 292us/sample - loss: 0.0493 - mean_absolute_error: 0.1483 - acc: 0.0016\n",
      "Epoch 1866/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0465 - mean_absolute_error: 0.1410 - acc: 0.0016\n",
      "Epoch 1867/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0748 - mean_absolute_error: 0.1917 - acc: 0.0016\n",
      "Epoch 1868/2000\n",
      "3685/3685 [==============================] - 1s 292us/sample - loss: 0.0620 - mean_absolute_error: 0.1691 - acc: 0.0016\n",
      "Epoch 1869/2000\n",
      "3685/3685 [==============================] - 1s 288us/sample - loss: 0.0512 - mean_absolute_error: 0.1505 - acc: 0.0016\n",
      "Epoch 1870/2000\n",
      "3685/3685 [==============================] - 1s 297us/sample - loss: 0.0492 - mean_absolute_error: 0.1464 - acc: 0.0016\n",
      "Epoch 1871/2000\n",
      "3685/3685 [==============================] - 1s 285us/sample - loss: 0.0552 - mean_absolute_error: 0.1569 - acc: 0.0016\n",
      "Epoch 1872/2000\n",
      "3685/3685 [==============================] - 1s 297us/sample - loss: 0.0551 - mean_absolute_error: 0.1613 - acc: 0.0016\n",
      "Epoch 1873/2000\n",
      "3685/3685 [==============================] - 1s 329us/sample - loss: 0.0583 - mean_absolute_error: 0.1699 - acc: 0.0016\n",
      "Epoch 1874/2000\n",
      "3685/3685 [==============================] - 1s 305us/sample - loss: 0.0823 - mean_absolute_error: 0.2107 - acc: 0.0016\n",
      "Epoch 1875/2000\n",
      "3685/3685 [==============================] - 1s 290us/sample - loss: 0.0527 - mean_absolute_error: 0.1565 - acc: 0.0016\n",
      "Epoch 1876/2000\n",
      "3685/3685 [==============================] - 1s 296us/sample - loss: 0.0510 - mean_absolute_error: 0.1523 - acc: 0.0016\n",
      "Epoch 1877/2000\n",
      "3685/3685 [==============================] - 1s 290us/sample - loss: 0.0463 - mean_absolute_error: 0.1411 - acc: 0.0016\n",
      "Epoch 1878/2000\n",
      "3685/3685 [==============================] - 1s 287us/sample - loss: 0.0671 - mean_absolute_error: 0.1846 - acc: 0.0016\n",
      "Epoch 1879/2000\n",
      "3685/3685 [==============================] - 1s 298us/sample - loss: 0.0670 - mean_absolute_error: 0.1776 - acc: 0.0016\n",
      "Epoch 1880/2000\n",
      "3685/3685 [==============================] - 1s 278us/sample - loss: 0.0553 - mean_absolute_error: 0.1586 - acc: 0.0016\n",
      "Epoch 1881/2000\n",
      "3685/3685 [==============================] - 1s 278us/sample - loss: 0.0602 - mean_absolute_error: 0.1654 - acc: 0.0016\n",
      "Epoch 1882/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0563 - mean_absolute_error: 0.1649 - acc: 0.0016\n",
      "Epoch 1883/2000\n",
      "3685/3685 [==============================] - 1s 304us/sample - loss: 0.0587 - mean_absolute_error: 0.1711 - acc: 0.0016\n",
      "Epoch 1884/2000\n",
      "3685/3685 [==============================] - 1s 295us/sample - loss: 0.0769 - mean_absolute_error: 0.1962 - acc: 0.0016\n",
      "Epoch 1885/2000\n",
      "3685/3685 [==============================] - 1s 280us/sample - loss: 0.0526 - mean_absolute_error: 0.1526 - acc: 0.0016\n",
      "Epoch 1886/2000\n",
      "3685/3685 [==============================] - 1s 294us/sample - loss: 0.0581 - mean_absolute_error: 0.1657 - acc: 0.0016\n",
      "Epoch 1887/2000\n",
      "3685/3685 [==============================] - 1s 298us/sample - loss: 0.0593 - mean_absolute_error: 0.1627 - acc: 0.0016\n",
      "Epoch 1888/2000\n",
      "3685/3685 [==============================] - 1s 303us/sample - loss: 0.0519 - mean_absolute_error: 0.1567 - acc: 0.0016\n",
      "Epoch 1889/2000\n",
      "3685/3685 [==============================] - 1s 282us/sample - loss: 0.0522 - mean_absolute_error: 0.1483 - acc: 0.0016\n",
      "Epoch 1890/2000\n",
      "3685/3685 [==============================] - 1s 284us/sample - loss: 0.0662 - mean_absolute_error: 0.1788 - acc: 0.0016\n",
      "Epoch 1891/2000\n",
      "3685/3685 [==============================] - 1s 293us/sample - loss: 0.0644 - mean_absolute_error: 0.1741 - acc: 0.0016\n",
      "Epoch 1892/2000\n",
      "3685/3685 [==============================] - 1s 286us/sample - loss: 0.0652 - mean_absolute_error: 0.1793 - acc: 0.0016\n",
      "Epoch 1893/2000\n",
      "3685/3685 [==============================] - 1s 302us/sample - loss: 0.0584 - mean_absolute_error: 0.1661 - acc: 0.0016\n",
      "Epoch 1894/2000\n",
      "3685/3685 [==============================] - 1s 313us/sample - loss: 0.0435 - mean_absolute_error: 0.1369 - acc: 0.0016\n",
      "Epoch 1895/2000\n",
      "3685/3685 [==============================] - 1s 282us/sample - loss: 0.0525 - mean_absolute_error: 0.1568 - acc: 0.0016\n",
      "Epoch 1896/2000\n",
      "3685/3685 [==============================] - 1s 297us/sample - loss: 0.0425 - mean_absolute_error: 0.1364 - acc: 0.0016\n",
      "Epoch 1897/2000\n",
      "3685/3685 [==============================] - 1s 298us/sample - loss: 0.0628 - mean_absolute_error: 0.1683 - acc: 0.0016\n",
      "Epoch 1898/2000\n",
      "3685/3685 [==============================] - 1s 286us/sample - loss: 0.0545 - mean_absolute_error: 0.1540 - acc: 0.0016\n",
      "Epoch 1899/2000\n",
      "3685/3685 [==============================] - 1s 280us/sample - loss: 0.0532 - mean_absolute_error: 0.1592 - acc: 0.0016\n",
      "Epoch 1900/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0533 - mean_absolute_error: 0.1575 - acc: 0.0016\n",
      "Epoch 1901/2000\n",
      "3685/3685 [==============================] - 1s 301us/sample - loss: 0.0877 - mean_absolute_error: 0.2052 - acc: 0.0016\n",
      "Epoch 1902/2000\n",
      "3685/3685 [==============================] - 1s 306us/sample - loss: 0.0490 - mean_absolute_error: 0.1473 - acc: 0.0016\n",
      "Epoch 1903/2000\n",
      "3685/3685 [==============================] - 1s 283us/sample - loss: 0.0593 - mean_absolute_error: 0.1639 - acc: 0.0016\n",
      "Epoch 1904/2000\n",
      "3685/3685 [==============================] - 1s 278us/sample - loss: 0.0768 - mean_absolute_error: 0.1891 - acc: 0.0016\n",
      "Epoch 1905/2000\n",
      "3685/3685 [==============================] - 1s 296us/sample - loss: 0.0609 - mean_absolute_error: 0.1660 - acc: 0.0016\n",
      "Epoch 1906/2000\n",
      "3685/3685 [==============================] - 1s 292us/sample - loss: 0.0509 - mean_absolute_error: 0.1482 - acc: 0.0016\n",
      "Epoch 1907/2000\n",
      "3685/3685 [==============================] - 1s 285us/sample - loss: 0.0540 - mean_absolute_error: 0.1534 - acc: 0.0016\n",
      "Epoch 1908/2000\n",
      "3685/3685 [==============================] - 1s 286us/sample - loss: 0.0445 - mean_absolute_error: 0.1372 - acc: 0.0016\n",
      "Epoch 1909/2000\n",
      "3685/3685 [==============================] - 1s 276us/sample - loss: 0.0591 - mean_absolute_error: 0.1742 - acc: 0.0016\n",
      "Epoch 1910/2000\n",
      "3685/3685 [==============================] - 1s 302us/sample - loss: 0.0617 - mean_absolute_error: 0.1704 - acc: 0.0016\n",
      "Epoch 1911/2000\n",
      "3685/3685 [==============================] - 1s 291us/sample - loss: 0.0693 - mean_absolute_error: 0.1845 - acc: 0.0016\n",
      "Epoch 1912/2000\n",
      "3685/3685 [==============================] - 1s 287us/sample - loss: 0.0656 - mean_absolute_error: 0.1769 - acc: 0.0016\n",
      "Epoch 1913/2000\n",
      "3685/3685 [==============================] - 1s 280us/sample - loss: 0.0608 - mean_absolute_error: 0.1695 - acc: 0.0016\n",
      "Epoch 1914/2000\n",
      "3685/3685 [==============================] - 1s 291us/sample - loss: 0.0610 - mean_absolute_error: 0.1694 - acc: 0.0016\n",
      "Epoch 1915/2000\n",
      "3685/3685 [==============================] - 1s 282us/sample - loss: 0.0564 - mean_absolute_error: 0.1568 - acc: 0.0016\n",
      "Epoch 1916/2000\n",
      "3685/3685 [==============================] - 1s 309us/sample - loss: 0.0794 - mean_absolute_error: 0.1972 - acc: 0.0016\n",
      "Epoch 1917/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0551 - mean_absolute_error: 0.1557 - acc: 0.0016\n",
      "Epoch 1918/2000\n",
      "3685/3685 [==============================] - 1s 280us/sample - loss: 0.0623 - mean_absolute_error: 0.1705 - acc: 0.0016\n",
      "Epoch 1919/2000\n",
      "3685/3685 [==============================] - 1s 320us/sample - loss: 0.0645 - mean_absolute_error: 0.1725 - acc: 0.0016\n",
      "Epoch 1920/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0592 - mean_absolute_error: 0.1659 - acc: 0.0016\n",
      "Epoch 1921/2000\n",
      "3685/3685 [==============================] - 1s 289us/sample - loss: 0.0511 - mean_absolute_error: 0.1511 - acc: 0.0016\n",
      "Epoch 1922/2000\n",
      "3685/3685 [==============================] - 1s 278us/sample - loss: 0.0431 - mean_absolute_error: 0.1365 - acc: 0.0016\n",
      "Epoch 1923/2000\n",
      "3685/3685 [==============================] - 1s 284us/sample - loss: 0.0599 - mean_absolute_error: 0.1728 - acc: 0.0016\n",
      "Epoch 1924/2000\n",
      "3685/3685 [==============================] - 1s 296us/sample - loss: 0.0556 - mean_absolute_error: 0.1610 - acc: 0.0016\n",
      "Epoch 1925/2000\n",
      "3685/3685 [==============================] - 1s 296us/sample - loss: 0.0725 - mean_absolute_error: 0.1831 - acc: 0.0016\n",
      "Epoch 1926/2000\n",
      "3685/3685 [==============================] - 1s 286us/sample - loss: 0.0593 - mean_absolute_error: 0.1622 - acc: 0.0016\n",
      "Epoch 1927/2000\n",
      "3685/3685 [==============================] - 1s 282us/sample - loss: 0.0591 - mean_absolute_error: 0.1667 - acc: 0.0016\n",
      "Epoch 1928/2000\n",
      "3685/3685 [==============================] - 1s 302us/sample - loss: 0.0541 - mean_absolute_error: 0.1561 - acc: 0.0016\n",
      "Epoch 1929/2000\n",
      "3685/3685 [==============================] - 1s 290us/sample - loss: 0.0548 - mean_absolute_error: 0.1580 - acc: 0.0016\n",
      "Epoch 1930/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0569 - mean_absolute_error: 0.1624 - acc: 0.0016\n",
      "Epoch 1931/2000\n",
      "3685/3685 [==============================] - 1s 276us/sample - loss: 0.0531 - mean_absolute_error: 0.1565 - acc: 0.0016\n",
      "Epoch 1932/2000\n",
      "3685/3685 [==============================] - 1s 301us/sample - loss: 0.0560 - mean_absolute_error: 0.1618 - acc: 0.0016\n",
      "Epoch 1933/2000\n",
      "3685/3685 [==============================] - 1s 318us/sample - loss: 0.0774 - mean_absolute_error: 0.1924 - acc: 0.0016\n",
      "Epoch 1934/2000\n",
      "3685/3685 [==============================] - 1s 317us/sample - loss: 0.0535 - mean_absolute_error: 0.1557 - acc: 0.0016\n",
      "Epoch 1935/2000\n",
      "3685/3685 [==============================] - 1s 309us/sample - loss: 0.0432 - mean_absolute_error: 0.1360 - acc: 0.0016\n",
      "Epoch 1936/2000\n",
      "3685/3685 [==============================] - 1s 290us/sample - loss: 0.0514 - mean_absolute_error: 0.1576 - acc: 0.0016\n",
      "Epoch 1937/2000\n",
      "3685/3685 [==============================] - 1s 292us/sample - loss: 0.0470 - mean_absolute_error: 0.1448 - acc: 0.0016\n",
      "Epoch 1938/2000\n",
      "3650/3685 [============================>.] - ETA: 0s - loss: 0.0753 - mean_absolute_error: 0.1920 - acc: 0.0013685/3685 [==============================] - 1s 285us/sample - loss: 0.0755 - mean_absolute_error: 0.1921 - acc: 0.0016\n",
      "Epoch 1939/2000\n",
      "3685/3685 [==============================] - 1s 305us/sample - loss: 0.0700 - mean_absolute_error: 0.1840 - acc: 0.0016\n",
      "Epoch 1940/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0758 - mean_absolute_error: 0.1720 - acc: 0.0016\n",
      "Epoch 1941/2000\n",
      "3685/3685 [==============================] - 1s 279us/sample - loss: 0.0692 - mean_absolute_error: 0.1731 - acc: 0.0016\n",
      "Epoch 1942/2000\n",
      "3685/3685 [==============================] - 1s 304us/sample - loss: 0.0629 - mean_absolute_error: 0.1698 - acc: 0.0016\n",
      "Epoch 1943/2000\n",
      "3685/3685 [==============================] - 1s 306us/sample - loss: 0.0511 - mean_absolute_error: 0.1494 - acc: 0.0016\n",
      "Epoch 1944/2000\n",
      "3685/3685 [==============================] - 1s 288us/sample - loss: 0.0830 - mean_absolute_error: 0.1961 - acc: 0.0016\n",
      "Epoch 1945/2000\n",
      "3685/3685 [==============================] - 1s 280us/sample - loss: 0.0653 - mean_absolute_error: 0.1733 - acc: 0.0016\n",
      "Epoch 1946/2000\n",
      "3685/3685 [==============================] - 1s 283us/sample - loss: 0.0462 - mean_absolute_error: 0.1414 - acc: 0.0016\n",
      "Epoch 1947/2000\n",
      "3685/3685 [==============================] - 1s 289us/sample - loss: 0.0511 - mean_absolute_error: 0.1482 - acc: 0.0016\n",
      "Epoch 1948/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0595 - mean_absolute_error: 0.1666 - acc: 0.0016\n",
      "Epoch 1949/2000\n",
      "3685/3685 [==============================] - 1s 283us/sample - loss: 0.0863 - mean_absolute_error: 0.2058 - acc: 0.0016\n",
      "Epoch 1950/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0521 - mean_absolute_error: 0.1542 - acc: 0.0016\n",
      "Epoch 1951/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0613 - mean_absolute_error: 0.1710 - acc: 0.0016\n",
      "Epoch 1952/2000\n",
      "3685/3685 [==============================] - 1s 285us/sample - loss: 0.0487 - mean_absolute_error: 0.1465 - acc: 0.0016\n",
      "Epoch 1953/2000\n",
      "3685/3685 [==============================] - 1s 300us/sample - loss: 0.0540 - mean_absolute_error: 0.1537 - acc: 0.0016\n",
      "Epoch 1954/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0502 - mean_absolute_error: 0.1517 - acc: 0.0016\n",
      "Epoch 1955/2000\n",
      "3685/3685 [==============================] - 1s 278us/sample - loss: 0.0494 - mean_absolute_error: 0.1483 - acc: 0.0016\n",
      "Epoch 1956/2000\n",
      "3685/3685 [==============================] - 1s 302us/sample - loss: 0.0561 - mean_absolute_error: 0.1673 - acc: 0.0016\n",
      "Epoch 1957/2000\n",
      "3685/3685 [==============================] - 1s 292us/sample - loss: 0.0503 - mean_absolute_error: 0.1532 - acc: 0.0016\n",
      "Epoch 1958/2000\n",
      "3685/3685 [==============================] - 1s 287us/sample - loss: 0.0614 - mean_absolute_error: 0.1727 - acc: 0.0016\n",
      "Epoch 1959/2000\n",
      "3685/3685 [==============================] - 1s 278us/sample - loss: 0.0523 - mean_absolute_error: 0.1548 - acc: 0.0016\n",
      "Epoch 1960/2000\n",
      "3685/3685 [==============================] - 1s 296us/sample - loss: 0.0511 - mean_absolute_error: 0.1465 - acc: 0.0016\n",
      "Epoch 1961/2000\n",
      "3685/3685 [==============================] - 1s 290us/sample - loss: 0.0647 - mean_absolute_error: 0.1772 - acc: 0.0016\n",
      "Epoch 1962/2000\n",
      "3685/3685 [==============================] - 1s 298us/sample - loss: 0.0490 - mean_absolute_error: 0.1483 - acc: 0.0016\n",
      "Epoch 1963/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0462 - mean_absolute_error: 0.1400 - acc: 0.0016\n",
      "Epoch 1964/2000\n",
      "3685/3685 [==============================] - 1s 279us/sample - loss: 0.0588 - mean_absolute_error: 0.1737 - acc: 0.0016\n",
      "Epoch 1965/2000\n",
      "3685/3685 [==============================] - 1s 295us/sample - loss: 0.0751 - mean_absolute_error: 0.1919 - acc: 0.0016\n",
      "Epoch 1966/2000\n",
      "3685/3685 [==============================] - 1s 283us/sample - loss: 0.0532 - mean_absolute_error: 0.1556 - acc: 0.0016\n",
      "Epoch 1967/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0563 - mean_absolute_error: 0.1642 - acc: 0.0016\n",
      "Epoch 1968/2000\n",
      "3685/3685 [==============================] - 1s 279us/sample - loss: 0.0593 - mean_absolute_error: 0.1698 - acc: 0.0016\n",
      "Epoch 1969/2000\n",
      "3685/3685 [==============================] - 1s 280us/sample - loss: 0.0480 - mean_absolute_error: 0.1446 - acc: 0.0016\n",
      "Epoch 1970/2000\n",
      "3685/3685 [==============================] - 1s 317us/sample - loss: 0.0495 - mean_absolute_error: 0.1473 - acc: 0.0016\n",
      "Epoch 1971/2000\n",
      "3685/3685 [==============================] - 1s 298us/sample - loss: 0.0486 - mean_absolute_error: 0.1531 - acc: 0.0016\n",
      "Epoch 1972/2000\n",
      "3685/3685 [==============================] - 1s 283us/sample - loss: 0.0649 - mean_absolute_error: 0.1832 - acc: 0.0016\n",
      "Epoch 1973/2000\n",
      "3685/3685 [==============================] - 1s 282us/sample - loss: 0.0685 - mean_absolute_error: 0.1853 - acc: 0.0016\n",
      "Epoch 1974/2000\n",
      "3685/3685 [==============================] - 1s 287us/sample - loss: 0.0668 - mean_absolute_error: 0.1711 - acc: 0.0016\n",
      "Epoch 1975/2000\n",
      "3685/3685 [==============================] - 1s 297us/sample - loss: 0.0813 - mean_absolute_error: 0.1911 - acc: 0.0016\n",
      "Epoch 1976/2000\n",
      "3685/3685 [==============================] - 1s 299us/sample - loss: 0.0701 - mean_absolute_error: 0.1801 - acc: 0.0016\n",
      "Epoch 1977/2000\n",
      "3685/3685 [==============================] - 1s 286us/sample - loss: 0.0491 - mean_absolute_error: 0.1447 - acc: 0.0016\n",
      "Epoch 1978/2000\n",
      "3685/3685 [==============================] - 1s 276us/sample - loss: 0.0500 - mean_absolute_error: 0.1520 - acc: 0.0016\n",
      "Epoch 1979/2000\n",
      "3685/3685 [==============================] - 1s 298us/sample - loss: 0.0468 - mean_absolute_error: 0.1459 - acc: 0.0016\n",
      "Epoch 1980/2000\n",
      "3685/3685 [==============================] - 1s 287us/sample - loss: 0.0634 - mean_absolute_error: 0.1732 - acc: 0.0016\n",
      "Epoch 1981/2000\n",
      "3685/3685 [==============================] - 1s 306us/sample - loss: 0.0622 - mean_absolute_error: 0.1696 - acc: 0.0016\n",
      "Epoch 1982/2000\n",
      "3685/3685 [==============================] - 1s 282us/sample - loss: 0.0510 - mean_absolute_error: 0.1530 - acc: 0.0016\n",
      "Epoch 1983/2000\n",
      "3685/3685 [==============================] - 1s 279us/sample - loss: 0.0586 - mean_absolute_error: 0.1663 - acc: 0.0016\n",
      "Epoch 1984/2000\n",
      "3685/3685 [==============================] - 1s 313us/sample - loss: 0.0767 - mean_absolute_error: 0.1948 - acc: 0.0016\n",
      "Epoch 1985/2000\n",
      "3685/3685 [==============================] - 1s 297us/sample - loss: 0.0529 - mean_absolute_error: 0.1540 - acc: 0.0016\n",
      "Epoch 1986/2000\n",
      "3685/3685 [==============================] - 1s 283us/sample - loss: 0.0444 - mean_absolute_error: 0.1378 - acc: 0.0016\n",
      "Epoch 1987/2000\n",
      "3685/3685 [==============================] - 1s 295us/sample - loss: 0.0580 - mean_absolute_error: 0.1659 - acc: 0.0016\n",
      "Epoch 1988/2000\n",
      "3685/3685 [==============================] - 1s 294us/sample - loss: 0.0601 - mean_absolute_error: 0.1691 - acc: 0.0016\n",
      "Epoch 1989/2000\n",
      "3685/3685 [==============================] - 1s 288us/sample - loss: 0.0514 - mean_absolute_error: 0.1502 - acc: 0.0016\n",
      "Epoch 1990/2000\n",
      "3685/3685 [==============================] - 1s 296us/sample - loss: 0.0485 - mean_absolute_error: 0.1498 - acc: 0.0016\n",
      "Epoch 1991/2000\n",
      "3685/3685 [==============================] - 1s 281us/sample - loss: 0.0445 - mean_absolute_error: 0.1425 - acc: 0.0016\n",
      "Epoch 1992/2000\n",
      "3685/3685 [==============================] - 1s 286us/sample - loss: 0.0634 - mean_absolute_error: 0.1672 - acc: 0.0016\n",
      "Epoch 1993/2000\n",
      "3685/3685 [==============================] - 1s 321us/sample - loss: 0.0667 - mean_absolute_error: 0.1758 - acc: 0.0016\n",
      "Epoch 1994/2000\n",
      "3685/3685 [==============================] - 1s 326us/sample - loss: 0.0698 - mean_absolute_error: 0.1794 - acc: 0.0016\n",
      "Epoch 1995/2000\n",
      "3685/3685 [==============================] - 1s 325us/sample - loss: 0.0662 - mean_absolute_error: 0.1771 - acc: 0.0016\n",
      "Epoch 1996/2000\n",
      "3685/3685 [==============================] - 1s 302us/sample - loss: 0.0666 - mean_absolute_error: 0.1748 - acc: 0.0016\n",
      "Epoch 1997/2000\n",
      "3685/3685 [==============================] - 1s 295us/sample - loss: 0.0536 - mean_absolute_error: 0.1578 - acc: 0.0016\n",
      "Epoch 1998/2000\n",
      "3685/3685 [==============================] - 1s 289us/sample - loss: 0.0591 - mean_absolute_error: 0.1669 - acc: 0.0016\n",
      "Epoch 1999/2000\n",
      "3685/3685 [==============================] - 1s 306us/sample - loss: 0.0493 - mean_absolute_error: 0.1492 - acc: 0.0016\n",
      "Epoch 2000/2000\n",
      "3685/3685 [==============================] - 1s 280us/sample - loss: 0.0523 - mean_absolute_error: 0.1513 - acc: 0.0016\n"
     ]
    }
   ],
   "source": [
    "history = keras_model.fit(X_train,y_train,epochs=2000, batch_size=50,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondaccb0c1180edc481782339d9fb6e461e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
